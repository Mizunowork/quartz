---
title: Research Fellow(s)
date: 08.23.24
tags:
  - positions
  - research
  - announcements
---
(Remote, Fellowship)

## About the Role
We're always on the lookout for talented students and independent researchers interested in qualitative and qualitative projects adjacent to our mission and products. Possible domains of inquiry include but aren't limited to machine learning, alignment, cryptography, the cognitive sciences, and other interdisciplinary fields of study.

Our fellowships can accommodate stipends or grants for a variety of formats, timelines, and deliverables (one of or a mix of publishable research, OSS code, philosophical investigation, and/or proprietary company tech, etc). We believe that high-trust and autonomy form the foundation of good research culture.

If collaborating with Plastic to push the boundaries of artificial intelligence, digital identity, radically decentralized alignment, synthetic human representations, frontier security, positive sum data practices, autonomous agents, etc excites you intellectually, please don't hesitate to reach out. We'd love to support your work.

## About You
- High alignment with Plastic Labs' intellectual space
- Possible research interest in representation engineering, control vectors, prompt optimization, sparse auto-encoders, etc
- Possible research interest in agentic frameworks, autonomous agents, emergent behaviors, theory of mind, identity, alignment, etc
- Possible research interest in the cognitive sciences or other adjacent interdisciplinary fields
- Possible research interest in distributed systems, security, decentralized protocols, or cryptography
- Possible research interest in anything explored on [our blog](https://blog.plasticlabs.ai)

## How to Apply
Please send the following to research@plasticlabs.ai:
- **Resume/CV** in whatever form it exists (PDF, LinkedIn, website, etc)
- **Portfolio** of notable work (GitHub, pubs, ArXiv, blog, X, etc)
- **Statement** of alignment specific to Plastic Labs--how do you identify with our mission, how can you contribute, etc? (points for brief, substantive, heterodox)
- **Proposal** for scope of research adjacent to our mission (approach, needs, budget, timeline, capacity, milestones, deliverables, Plastic intersections, etc)

Applications without these 4 items won't be considered, but be sure to optimize for speed over perfection. We can help with specifics, but flesh out as much as you can, even if it might change. If relevant, be sure to credit the LLM you used.

And it can't hurt to [join Discord](https://discord.gg/plasticlabs) and introduce yourself or engage with [our GitHub](https://github.com/plastic-labs).

## Selected Research We're Tracking
[Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm](https://arxiv.org/pdf/2102.07350)  
[Theory of Mind May Have Spontaneously Emerged in Large Language Models](https://arxiv.org/pdf/2302.02083v3)  
[Think Twice: Perspective-Taking Improved Large Language Models' Theory-of-Mind Capabilities](https://arxiv.org/pdf/2311.10227)
[Representation Engineering: A Top-Down Approach to AI Transparency](https://arxiv.org/abs/2310.01405)
[Theia Vogel's post on Representation Engineering Mistral 7B an Acid Trip](https://vgel.me/posts/representation-engineering/)  
[A Roadmap to Pluralistic Alignment](https://arxiv.org/abs/2402.05070)  
[Open-Endedness is Essential for Artificial Superhuman Intelligence](https://arxiv.org/pdf/2406.04268)  
[Simulators](https://generative.ink/posts/simulators/)  
[Extended Mind Transformers](https://arxiv.org/pdf/2406.02332)  
[Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models](https://arxiv.org/abs/2310.06983)  
[Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073)  
[Claude's Character](https://www.anthropic.com/research/claude-character)  
[Language Models Represent Space and Time](https://arxiv.org/pdf/2310.02207)  
[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)  
[Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge](https://arxiv.org/abs/2407.19594)  
[Spontaneous Reward Hacking in Iterative Self-Refinement](https://arxiv.org/abs/2407.04549)  
[... accompanying twitter thread](https://x.com/JanePan_/status/1813208688343052639)  


(Back to [[Work at Plastic]])