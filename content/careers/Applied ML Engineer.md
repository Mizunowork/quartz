---
title: Applied ML Engineer
date: 02.13.25
tags:
  - positions
  - product
  - dev
  - announcements
---

(NYC, Full-Time)

## About the Role
We're searching for an applied machine learning engineer excited to work on the ML side of [Honcho](https://honcho.dev). You'll work alongside our interdisciplinary team to transform novel ideas into production systems that help LLMs understand and align with individual users.

This role requires a strong engineer who can rapidly prototype and ship ML systems. The pace of the LLM space is staggering - we need someone with a hacker mentality who is excited about diving into papers/codebases, implementing novel methods at breakneck speed, and figuring out what actually works. Our team is small and fast-moving, so you'll have the freedom to experiment widely and ship impactful features quickly.


## About You
- 2-3 years applied LLM experience or equivalent
- Proficiency with a popular Python ML library (e.g PyTorch, TF, JAX, HF transformers, etc)
- Experience building LLM systems
- Experience with post-training methods & implementing LLM papers
- Comfortable in Unix environment + attendant command line tools (Git, Docker, etc)
- Up to date on OS AI community & technologies 
- High cultural alignment with Plastic Labs' ethos
- In NYC or willing to move to NYC
- Complementary interest or experience specific to reinforcement learning, representation engineering, control vectors, prompt optimization, sparse auto-encoders, agentic frameworks, emergent behaviors, theory of mind, identity a plus
- Complementary background in cognitive sciences (cs, linguistics, neuroscience, philosophy, & psychology) or other adjacent interdisciplinary fields a plus

## How to Apply
Please send the following to research@plasticlabs.ai:
- **Resume/CV** in whatever form it exists (PDF, LinkedIn, website, etc)
- **Portfolio** of notable work (GitHub, pubs, ArXiv, blog, X, etc)
- **Statement** of alignment specific to Plastic Labs--how do you identify with our mission, how can you contribute, etc? (points for brief, substantive, heterodox)

Applications without these 3 items won't be considered, but be sure to optimize for speed over perfection. If relevant, be sure to credit the LLM you used.

And it can't hurt to [join Discord](https://discord.gg/plasticlabs) and introduce yourself or engage with [our GitHub](https://github.com/plastic-labs).

## Research We're Excited About
[s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393)
[Neural Networks Are Elastic Origami!](https://youtu.be/l3O2J3LMxqI?si=bhodv2c7GG75N2Ku)
[Titans: Learning to Memorize at Test Time](https://arxiv.org/abs/2501.00663v1)
[Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning](https://arxiv.org/abs/2412.13631)
[Generative Agent Simulations of 1,000 People](https://arxiv.org/abs/2411.10109)
[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
[Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains](https://arxiv.org/abs/2501.05707)
[Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm](https://arxiv.org/pdf/2102.07350)  
[Theory of Mind May Have Spontaneously Emerged in Large Language Models](https://arxiv.org/pdf/2302.02083v3)  
[Think Twice: Perspective-Taking Improved Large Language Models' Theory-of-Mind Capabilities](https://arxiv.org/pdf/2311.10227)
[Representation Engineering: A Top-Down Approach to AI Transparency](https://arxiv.org/abs/2310.01405)
[Theia Vogel's post on Representation Engineering Mistral 7B an Acid Trip](https://vgel.me/posts/representation-engineering/)  
[A Roadmap to Pluralistic Alignment](https://arxiv.org/abs/2402.05070)  
[Open-Endedness is Essential for Artificial Superhuman Intelligence](https://arxiv.org/pdf/2406.04268)  
[Simulators](https://generative.ink/posts/simulators/)  
[Extended Mind Transformers](https://arxiv.org/pdf/2406.02332)  
[Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models](https://arxiv.org/abs/2310.06983)  
[Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073)  
[Claude's Character](https://www.anthropic.com/research/claude-character)  
[Language Models Represent Space and Time](https://arxiv.org/pdf/2310.02207)  
[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)  
[Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge](https://arxiv.org/abs/2407.19594)  
[Cyborgism](https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism)  
[Spontaneous Reward Hacking in Iterative Self-Refinement](https://arxiv.org/abs/2407.04549)  
[... accompanying twitter thread](https://x.com/JanePan_/status/1813208688343052639)  


(Back to [[Work at Plastic]])
